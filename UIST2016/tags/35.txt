Rig Animation with a Tangible and Modular Input Device
Oliver Glauser
ETH Zurich
oliver.glauser@inf.ethz.ch

Benedek Vartok
ETH Zurich

Wan-Chun Ma
Activision, Inc.

Daniele Panozzo
New York University

Alec Jacobson
Columbia University

Otmar Hilliges
ETH Zurich

Olga Sorkine-Hornung
ETH Zurich
ABSTRACT

We propose a novel approach to digital character animation,
combining the benefits of modular and tangible input devices
and sophisticated rig animation algorithms. With a symbiotic
software and hardware approach, we overcome limitations inherent to all previous tangible devices. It allows users to directly control complex rigs with 5-10 physical controls only.
These compact input device configurations - optimized for a
specific rig and a set of sample poses - are automatically generated by our algorithm. This avoids oversimplification of the
pose space and excessively bulky devices.

Figure 1. Illustration of our pipeline from input character to fluid tangible animation. The horse has 29 bones, controlled by 8 joints.

Author Keywords

Our approach (as described in detail in Glauser et al. [1]) allows novice users and experts to create animation sequences.
Results from a user study (see [1]) compare favorably to the
hardware design of Jacobson et al. [2] both in terms of accuracy and posing time, providing an average speed-up of 2×.
The method is integrated directly into Autodesk’s Maya R 3D
animation software and its open-source counterpart Blender.

Novel input devices; character articulation
ACM Classification Keywords

H.5.2 Information Interfaces & Presentation: User Interfaces
INTRODUCTION

For interactive character animation - as an alternative to classic mouse/keyboard interfaces - recent tangible input devices
promise direct and natural manipulation, but at the cost of either grossly simplifying the pose space or of accepting complex and bulky physical setups. In contrast, we present a
novel software/hardware approach co-designed to help animators traverse a large space of poses via fluid manipulation
of a tangible controller.

TECHNICAL CONTRIBUTION

The user provides a rigged 3D character with a sparse set of
sample poses (readily available online). Furthermore, the user
indicates the kit (number of joints and splitters) to use (Figure 1, left). Our algorithm then analyzes the rig and the poses,
identifying the DoFs with the most influence on pose reachability, weighted by the amount of controlled surface. Optimizing for direct control of these most important nodes, and
using only the available parts, a device configuration and assembly instructions are computed (Figure 1, middle). After
assembly the compact physical device is automatically bound
to the virtual rig and user inputs are mapped onto the rig.
Manipulating the device induces a similar deformation onto
the 3D character (Figure 1, right). In most cases the physical
configuration has significantly fewer DoFs than the rig while
still allowing to cover a large enough pose space as shown
in Figure 2. To maintain expressiveness and add details back
into the resulting motion, we use a pose space interpolation
scheme to synthesize detailed pose nuances.

Specifically, we contribute: (a) an algorithm to compute a device configuration and instructions to assemble it, using only
a small set of modules; (b) a novel hardware design, overcoming major limitations in prior work via a novel physical
angle parametrization; and (c) a method to bridge the disparity between the input device’s few degrees of freedom to the
character’s many control parameters.

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the Owner/Author.
Copyright is held by the owner/author(s).
UIST’16 Adjunct, October 16-19, 2016, Tokyo, Japan
ACM 978-1-4503-4531-6/16/10.
http://dx.doi.org/10.1145/2984751.2985696

Our hardware design, inspired by Jacobson et al. [2], follows
a modular approach, decomposing the control structure into

35

pose rig error [%]

100
80
60
40
20
0

0

5

10
15
20
joints in device [n]

25

Figure 4. Interactive assembly of the optimized device in Blender: The
user is interactively guided in assembling the optimized device by having
the already correctly connected parts of the device displayed in color and
the ones still missing in light grey.

30

Figure 2. Influence of joint number in the kit on pose accuracy. Generated devices for different kits are shown: A device of 12 parts (10 joints
and 2 splitters) allows to reduce the sample pose error by 98 %.
0

θ

−40
−60

ψ

−80

φ

Angle [°]

Jacobson et al. 14
Ours

Ours

−20

Figure 5. Example posing session of a bunny character, with a device
consisting of 3 joints and 1 splitter.
Jacobson et al. 14

0

−20
θ

−40
−60
−80
0s

novel algorithm suggests an optimized device configuration
and interactive assembly instructions (see Figure 4) for the
visitor.

ψ
φ
5s

10 s

15 s

20 s

25 s

30 s

Figure 3. Our physical angle parametrization allows for direct tracing
of geodesics. The joints of Jacobson et al. [2] force angular decomposition of rotations, resulting in a zig-zag pattern. Ours is also significantly
faster in reaching the target position.

We demonstrate how this optimized compact device with few
degrees of control is sufficient to pose a complex rig with
many degrees of freedom. It also allows to experience how
the novel joint design enables a more fluid and direct control
compared to state-of-the-art devices.

joints that measure 3D rotations, and splitters, which allow
for branching. This design enables dynamic rearrangement
of the parts into arbitrary topologies. However, one of the
main limitations of [2] is due to the mechanical joint design.
We propose a new joint design to overcome this limitation
and provide a much improved user-experience by allowing
for smoother and faster tracing of geodesics – both for individual joints (see Figure 3) and chains of joints. More details
on our novel joint design can be found in [1].

For easy reproducibility and to foster future work, we are releasing the open-hardware specification and the software implementations1 . For footage of the input device in action and
more results, we refer to the accompanying video.
ACKNOWLEDGMENTS

This work was supported in part by the SNF grant
200021 162958 and the ERC grant iModel (StG-2012306877). Alec Jacobson is funded in part by NSF grants IIS14-09286 and IIS-17257.

ENHANCEMENTS

Since Glauser et al. [1] we extended the software periphery of the input device with a Blender plugin that offers a
much improved user interaction, e.g., an interactive assembly
guide. And using an RBF (radial basis function) interpolation scheme (inspired by Sloan et al. [3]) leads to smoother
detailed pose nuances.

REFERENCES

1. Glauser, O., Ma, W.-C., Panozzo, D., Jacobson, A.,
Hilliges, O., and Sorkine-Hornung, O. Rig Animation
with a Tangible and Modular Input Device. ACM Trans.
Graph. 35, 4 (2016).
2. Jacobson, A., Panozzo, D., Glauser, O., Pradalier, C.,
Hilliges, O., and Sorkine-Hornung, O. Tangible and
modular input device for character articulation. ACM
Trans. Graph. 33, 4 (2014).

DEMO

Visitors have the opportunity to try our novel tangible and
modular user input device (example sequence in Figure 5).
With this tangible interface even visitors without any prior
experience in 3D animation are able to create short character
animation sequences in Blender.

3. Sloan, P.-P. J., Rose, III, C. F., and Cohen, M. F. Shape by
example. In Proceedings of the 2001 Symposium on
Interactive 3D Graphics, I3D ’01, ACM (New York, NY,
USA, 2001), 135–143.

Thanks to the modularity of the device, the visitor can choose
from a set of 3D characters. Additionally the size of the kit
(joints and splitters) can be varied. Based on these inputs our

1

36

http://oliglauser.github.io/atamid/

