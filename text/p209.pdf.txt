A Novel Real Time Monitor System of
3D Printing Layers for Better Slicing Parameter Setting
Yu-Kai Chiu
National Taiwan University
yukaichiu213@gmail.com

Hao-Yu Chang
National Taiwan University
hychang.cs00@g2.nctu.edu.tw

Yu-Hsuan Huang
National Taiwan University
yush.huang@gmail.com

Wan-Ling Yang
National Taiwan University
r04944014@ntu.edu.tw

Ming Ouhyoung
National Taiwan University
ming@csie.ntu.edu.tw
images and reconstruct the full-layer image simultaneously
during printing process. Further analysis and computer-aided
suggestion of parameters are possible with these information.

ABSTRACT

We proposed a novel real time monitor system of 3D printer
with dual cameras, which capture and reconstruct the printed
result layer by layer. With the reconstructed image, we can
apply computer vision technique to evaluate the difference
with the ideal path generate by G-code. The difference gives
us clues to classify which might be the possible factor of
the result. Hence we can produce advice to user for better
slicing parameter settings. We believe that this system can
give helps to beginner or users of 3D printer that struggle in
parameter settings in the future.

OUR APPROACH

Our goal is to compare every reconstructed layers of 3D
printing object with the ideal extruder path according to
the G-code generated by slicing software. G-code path
can be the ground truth of printing process while hardware
problem such as missing steps is eliminated. Our proposed
approach doesn’t consider the situation of hardware defects
because it is impractical to resolve the build defects by
modifying parameters. We only focus on the parameters in
3D printing. The compared result can offer clues for the
problem of printing, thus we can classify the issue through
this observation. Our study integrated a special designed
multiple cameras system with image processing algorithm to
address this problem, the flowchart is shown in Figure 1.

ACM Classification Keywords

I.3.8 [Computer Graphics]:Applications
Author Keywords

3D printer; dual camera; monitor system; slicing parameters;
machine vision;
INTRODUCTION

Over the few years, three dimensional printing has become a
very useful technology. However, it is not easy for users to
get started with. There are multiple parameters which can
affect the quality or durability of the printed objects. Users
have to observe the printing process manually to modify the
parameters. By observing the melted filament’s features and
its attaching style to the printing surface, we can get some
hints to improve the result.
To get the images during printing process, Sitthi-Amorn et
at.[1] placed a camera on the top view and scan the surface
of the platform after the whole layer is finished. However,
this approach can not get the immediate images and will
prolong the printing process. In our work, we present a
system with two near-field cameras that can record real time

Figure 1. System Flowchart

As shown in Figure 2a, two near-field cameras with 60 Hz
frame rate are positioned perpendicularly to each other and
closely around the extruder. This design can avoid occlusion
problem and reconstruct the path better in all directions by
processing the images from the 2 cameras.
Before the printing started, camera calibration is performed
to obtain the transform matrix of both cameras and the scale
between captured images and real distance. During the printing process, the position of extruder is tracked to locate the
image of melted filaments in Figure 2b. Then, we cropped
the image around the extruder for the reconstruction. Those
images can be warped to the top view of the printing layers

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the Owner/Author. Copyright is held by the owner/author(s).
UIST’16 Adjunct, October 16-19, 2016, Tokyo, Japan
ACM 978-1-4503-4531-6/16/10.
http://dx.doi.org/10.1145/2984751.2984773

209

Figure 2. (a) Our near-field multi-camera module positioned around the
extruder can (b) automatically track the extruder and crop the imageunder it during the printing process.

Figure 4. The layer images can be reconstructed from 2 cameras such
as the red part in (a) and (b), which will be compared with (c) the ideal
path from G-code.

by the transform matrix, we can get two warped image from
top view after this process. The warped images from 2 cameras can be combined proportionally according to the angle
of the path directions. We can use a weight function for the
proportion of the combination. Using the G-code information
and the speed setting of the printer, we can put those image
fragments on the correct position. We aligned the images by
applying edge detection, and shift them according to their offset. After the above process, we can reconstruct a top view of
the entire single layer.

is significantly improved after we changed the printing speed
Figure 4b.

The difference between the reconstructed layer images and
the ideal path can be calculated by standard computer vision
techniques such as edge detection, skeletonization and subtraction. The above information can represent the quality of
the printing result and give us the clue to modify the parameters for the next print.

Combining our system with the Machine Learning models,
we can categorize the problems of 3D printing and generate
better parameter settings to iteratively improve the printing
process. For the beginners, the wasted time before the first
success can be significantly decreased by utilizing our system.

CONCLUSION AND FUTURE WORK

Our proposed approach introduced a novel solution that can
help users to monitor the printed structures layer by layer
without prolonging the printing time. We can evaluate the
quality of the printed object by computer vision techniques to
compare reconstructed images with the ideal paths generated
from the G-code.

ACKNOWLEDGEMENTS

This work was partially supported by MOST 104-26228-002-002 (MediaTek Inc.), MOST 103-2218-E-002-025MY3, and MOST 105-2221-E-12D-MY2.
REFERENCES

1. Sitthi-Amorn, P., Ramos, J. E., Wangy, Y., Kwan, J., Lan,
J., Wang, W., and Matusik, W. Multifab: a machine vision
assisted platform for multi-material 3d printing. ACM
Transactions on Graphics (TOG) 34, 4 (2015), 129.

Figure 3. Difference between our recontructed image and ideal path. (a)
shows the case of the straight line, and (b) shows the case of corner

For example, in the case of straight line Figure 3a, we can
subtract image of the ideal path from reconstructed image to
get the difference between them. With the difference of the
image, we will be able to categorize the result. If the printed
filament is thicker than the ideal path, it is possible for the
case that the we should lower the temperature of the extruder,
and speed up the printing process. On the other side, if the
printed filament is thinner, we should probably slow down the
printing speed or raise the temperature of the extruder. We
can also make an observation of the corner Figure 3b. The
ideal case of the corner should contain two vertical edges, but
sometimes the result will be more like a curve. We can use
curve fitting to measure the printing error of the corner. If the
result is away from the ideal case, the printing speed might
be too fast or the stickiness of the filament to the lower layer
is too low.
We also skeletonize the reconstructed image to get the route
of the extruder. The layer showed in Figure 4a is failed due to
the printing speed according to the skeletonized path and the
corner fitting result on the upper-right corner. The thickness
of the straight line is also failed in other part. The quality

210

