ExtendedHand on Wheelchair
Yuki Asai, Yuta Ueda, Ryuichi Enomoto, Daisuke Iwai and Kosuke Sato
Graduate School of Engineering Science, Osaka University
1-3 Machikaneyama, Toyonaka, Osaka, Japan
{asai, ueda, enomoto}@sens.sys.es.osaka-u.ac.jp, {daisuke.iwai, sato}@sys.es.osaka-u.ac.jp
ABSTRACT

In this paper, we present a novel welfare system which utilizes a spatial augmented reality technique. Hand is a crucial component in human-human communication. For example, we can intuitively indicate an object or place by reaching and pointing it to nearby partners. Unfortunately, for
wheelchair users, such communication is often limited because their reaching ranges are narrow, and moving their bodies to the target is tiresome. To solve this issue, we propose a
novel wheelchair system on which a battery-powered mobile
projector is mounted. A user manipulates the projected virtual hand as an extension of the real one using a touch panel
equipped on an armrest of the wheelchair. We implement our
proposed system and demonstrate the effectiveness.
Author Keywords

Virtual hand; wheelchair; communication; tablet.
Figure 1. Communication support with our wheelchair system.

ACM Classification Keywords

H.5.2. Information Interfaces and Presentation (e.g. HCI):
User Interfaces

of our system can communicate with a partner with a wider
reaching area of a hand (Fig. 1).

INTRODUCTION

A wheelchair is one of the most important tool for people
with disabilities in their legs to move around. However, because wheelchairs require a certain amount of space to move,
users cannot approach to targets when there are not enough
space. As a result, wheelchair users cannot reach on the targets by their hands for communication. Therefore, it is difficult for them to communicate smoothly with other people.
To solve this important issue, we propose to mount a projector and a touch panel on a wheelchair. The projector superimposes a virtual hand image extended from the actual hand
which manipulates the virtual hand in real-time based on the
hand gesture on the touch panel. The projected virtual hand
manipulation as an extension of the user’s real hand was originally proposed by Ogawa et al. who realized the manipulation
using computer vision-based hand recognition technique [2].
On the other hand, we apply the touch panel to recognize the
user’s hand gestures to make the gesture recognition independent from environment light conditions. As a result, a user

Upon mounting a projector on a wheelchair, there is a problem that the projected region is limited and fixed to the front
of the wheelchair. This means that the reaching range of the
virtual hand is significantly limited. Therefore, we propose to
extend the projection range of the virtual hand by placing a
pan-tilt mirror in front of the projector. As a result, projected
images can be moved outside the frustum of the projector in
both vertical and horizontal directions. This technique allows
wheelchair users to manipulate their virtual hands in a wider
area and to reach distant targets with them without moving
nor turning their wheelchairs.
Collision with other people is a prominent concern for
wheelchair users. The mounted projector can be used to display an arrow that indicates a future path of the wheelchair on
the ground. Consequently, people surrounding the wheelchair
can intuitively notice its path and safely avoid the collision.
We also give an application using a virtual hand as appliances
manipulation. IoT (Internet of Things) era is coming, and
variety of appliances are connecting to the internet. In this
paper, we give an example to manipulate such appliances with
projected virtual hand.

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the Owner/Author. Copyright is held by the owner/author(s).
UIST’16 Adjunct, October 16-19, 2016, Tokyo, Japan
Copyright c ACM 978-1-4503-4531-6/16/10.
http://dx.doi.org/10.1145/2984751.2985738

SYSTEM OVERVIEW

Figure 2 shows our prototype system, consisting of an electric
wheelchair (Foldawheel, PW-999UL), a projector (ASUS,

147

Figure 3. Manipulation of the virtual hand: (upper left)Translation,
(upper right)Rotation, (lower left)Grasp, and (lower right)Pointing.
The original hand model is provided from c 26◦ C(license:https://
creativecommons.org/licenses/by/4.0/), we separate it into
several parts and use them.

Figure 2. System overview

P3B) and a tablet computer (Microsoft, Surface Pro 3). Servo
motor is controlled by an Arduino, which is connected to the
tablet computer. A command to the servo motor is sent via
the serial communication. We modified the wheelchair system so that we can control the wheelchair movement from the
tablet computer via wireless communication.

an amplified translation distance. The rotation of the virtual hand corresponds to the rotation of the users hand on
the screen. All fingers are stretched out or completely bended
respectively. In the case of one-point touch, the index finger
is only stretched and the others are bent.

EXTENSION OF A PROJECTABLE REGION

APPILICATIONS

On simply mounting a projector on wheelchair, the projected
region is fixed to the front of the wheelchair. As a result, the
reachable range of the projected virtual hand is considerably
restricted. Then, we propose to extend the projection range
of the virtual hand by placing a pan-tilt mirror in front of the
projector. This technique allows wheelchair users to obtain
a communication method with hand in a wider area. Users
can move the projected image in both vertical and horizontal
directions by flick gesture on the touch panel. While the projected area of the virtual hand is extended, there is a problem
that the projection image becomes diagonally when the projected area is moved in the horizontal direction. As a result,
two problems occur. Firstly, the direction of the virtual hand
is distorted. Secondly, the size of the virtual hand is changed.
In the current system, users need to correct the direction and
size of the virtual hand by setting values from a menu window
or by using presetting values in order to solve the problems.

We give two application examples using our system. First
example is the display of a wheelchair course. Dancu presented a map navigation system for a bike using the projector[1]. On the other hand, we propose to display a future
path of the wheelchair on the ground. By visualizing the
wheelchair course on the road surface, wheelchair users can
show their running direction to the people around. We expect to reduce the possibility of collision between wheelchair
users and other people. Second example is the appliances operation by using a virtual hand. In the near future, variety
of appliances are goning to connect to the internet. In such
situations, users can control the appliances in remote by the
projected hand. For instance, we move a cleaning robot to the
specified position by using the virtual hand.
CONCLUSION

In this paper, we developed a novel wheelchair equipped with
a projector, and proposed communication support using a virtual hand. Moreover, we presented application examples related to the proposed system and showed the feasibility of the
future. We expect that the life environment of the wheelchair
users is greatly improved.

INTERACTION TECHNIQUE
Wheelchair

When users touch the screen and move thier fingers, the
wheelchair moves in that direction. The number of touched
fingers does not matter. The wheelchair also can move right
or left forward. For example, the wheelchair moves right
forward if users move thier fingers to the right while the
wheelchair moves forward. users can stop the wheelchair by
leaving their fingers from the touch panel.

REFERENCES

1. Dancu, A., et al. Smart flashlight: map navigation using a
bike-mounted projector. In Proceedings of the 32nd
annual ACM conference on Human factors in computing
systems, ACM (2014), 3627–3630.

Virtual hand

2. Ogawa, S., et al. A reachable user interface by the
graphically extended hand. In The 1st IEEE Global
Conference on Consumer Electronics 2012, IEEE (2012),
210–211.

Fig. 3 shows the manipulation of the virtual hand. According to the 2D translation of users hand on the touch screen,
the virtual hand translates towards the same direction with

148

