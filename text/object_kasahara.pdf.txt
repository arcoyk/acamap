Smarter Objects:
Using AR technology to Program
Physical Objects and their Interactions
Valentin Heun

Abstract

Fluid Interfaces Group

The Smarter Objects system explores a new method for
interaction with everyday objects. The system
associates a virtual object with every physical object to
support an easy means of modifying the interface and
the behavior of that physical object as well as its
interactions with other "smarter objects". As a user
points a smart phone or tablet at a physical object, an
augmented reality (AR) application recognizes the
object and offers an intuitive graphical interface to
program the object's behavior and interactions with
other objects. Once reprogrammed, the Smarter Object
can then be operated with a simple tangible interface
(such as knobs, buttons, etc). As such Smarter Objects
combine the adaptability of digital objects with the
simple tangible interface of a physical object. We have
implemented several Smarter Objects and usage
scenarios demonstrating the potential of this approach.

MIT Media Laboratory
20 Ames Street
Cambridge, MA 02139 U.S.A.
heun@media.mit.edu
Shunichi Kasahara
Sony Corporation
MIT Media Laboratory
20 Ames Street
Cambridge, MA 02139 U.S.A.
shunichi.kasahara@jp.sony.com
Pattie Maes
Fluid Interfaces Group
MIT Media Laboratory
20 Ames Street
Cambridge, MA 02139 U.S.A.
pattie@media.mit.edu

Author Keywords
Augmented Reality; Ubiquitous Computing

ACM Classification Keywords
Copyright is held by the author/owner(s).
CHI 2013 Extended Abstracts, April 27–May 2, 2013, Paris, France.
ACM 978-1-xxxx-xxxx-xxxxxxxx.

H.5.2 User Interfaces; H.5.1 Multimedia Information
Systems

This paper presents a method for a seamless
combination of physical and virtual interfaces that can
enable every physical object to become “smarter” and
provide a greater breadth of functionality, while still
enabling a quick tactile interface. Such combination
enables the user to balance tactile and visual
awareness as well as allowing complex interactions and
adaptations.

Figure 1: Understanding and setup
are a small part of the overall
interaction with objects.

Figure 3: A graphical user interface presented on top of a
tangible user interface, in this case a light switch, is used to
modify the color of the room light. The tangible light switch is
used to turn the light on and off.

General Terms
Design; Human Factors

We propose Smarter Objects – a platform that allows
the user to understand and program physical objects
using a virtual representation through an augmented
reality based GUI (see Figure 3). Once the flexible
functionality of an object is understood and
programmed, the object can be operated in a tactile
way that requires minimal visual attention.
Furthermore, such objects can share their functionality
and enable interactions involving other physical or
virtual objects’ functionalities (see Figure 9,12,13).

Introduction
Figure 2: Using an iPad, a User
operates a GUI augmented on top of
a TUI in order to open a door. Green
and blue tags can be seen that
represent the components of a door.
They can be used to connect the
door’s functionality with other
objects.

In an Internet-enabled world, objects can be constantly
modified or programmed to behave in certain ways
typically by means of an embedded screen with
Graphical User Interface (GUI). While a GUI provides
great flexibility, the use of such an interface requires
the user’s complete visual attention.
In contrast, interfaces found on traditional electronic
products such as kitchen devices or garden tools are
unable to deliver the flexible interaction that screens
provide. However, these interfaces deliver continuous
tactile feedback and allow the user to interact with
everyday objects using muscle memory and a sense of
kinesthesia. To focus on the task, full visual attention is
not required. For example, a light switch can be
activated even in the dark.

Understand, Set up and Operate
There are three different interaction modes that need
to be considered in order to understand the advantages
of graphical and tangible user interfaces (TUI) of an
object (see Figure 1).
The first thing one does when using an object is to
understand its meaning and functionality. Once the
object is understood, it gets customized or
programmed to the user’s desire. For example, one first
needs to know the functionalities of a radio in order to
then program its settings such as preselected radio
stations. The assumption is that these steps require the
most visual interaction but represent just a small
amount of the full interaction with the object. The
largest part of a user interaction is the daily operation.

This action only needs minimal visual attention, as the
object is fully understood and is working as expected.
This interaction is memorized in gestures, skin feeling
and muscle memory. For example the radio does not
require the user’s visual attention.

Figure 4: Radio with its TUI
represented by a tuner and a volume
knob.

In contrast, computer interfaces are based on visual
feedback interaction rather than the tangible operation
we are used to with everyday objects. For example, to
turn on the radio on a smartphone, one needs to look
at the display. The concept of Smarter Objects allows
computation to be seamlessly incorporated into
everyday objects.

Related Work

Figure 5: A user operates the tuner
knob to choose from 8 tuner settings.

Figure 6: With an iPad a user augments
a GUI on top of the TUI

The I/O Bulbs [1] project explored how digital
information and connections that exist for physical
objects can be projected on top of surfaces or by
mapping digital information directly into physical
objects [2]. A social network for “lonely objects” [3]
explored the benefits of connecting objects with each
other to support the user in her or his daily decisionmaking. By filling the world with sensors [4] we can
blur the gap between the digital world and the real
world. The use of an Internet-0 [5] also enables low
power local computational networks that can be
connected to such sensors with the Internet or local
services.
It has been shown that a real image with augmented
interaction through the screen [6] can provide a better
intuitive interface than an abstraction of such a system
on a screen as well the usefulness of real time feedback
systems through tangible interfaces [7]. Augmented
interfaces have been used to remotely control
electronic devices in a home-use case [8][9]. The main

application of augmented reality in the area of real
objects at this point is the maintenance of machines,
supported by augmented in-time guidance
[10][11][12].
One can say that Augmented Reality at this point is
mainly focused on research to generate a better
understanding of real things [13] instead of enabling
the programming of the behavior and interface of the
physical world objects.

Prototype examples
Some initial hardware explorations of the Smarter
Objects concept include a door opener (see Figure 2),
light switches with reprogrammable color (see Figure
3), and simple sensors (see Figure 11). Smarter
Objects can couple the functionality of a simple tangible
radio with the advantages of a graphical media player
that supports all kinds of audio sources, playlists and
online radios. In its daily operation, such a radio can be
operated with two simple knobs (see figure 4, 5), one
for tuning and one for volume. Once the music should
be changed, a GUI can be used to get a better
understanding of the chosen songs, the available songs
and radio stations (see figure 6-8). Once a song is
selected, it can be dragged and dropped on a spot on
the tuning knob to reprogram that knob setting (see
Figure 10). All changes on the TUI have real time
influence on the GUI and vice versa.
To supply the radio with higher quality sound, it can be
connected with a speaker by simply drawing a line from
the radio to the speaker within the GUI (see Figure 9).
Once the finger is released, the devices are connected
and the speaker supports the radio sound (see Figure
12-13). A simple swipe gesture over the connecting line

cuts the connection and the devices are disconnected
again. Once the settings are determined, the radio can
be operated with only the TUI until the next
functionality setup is required (see Figure 14).

Figure 7: A user operates the TUI. His
manipulations on the TUI generate

Figure 11: A working prototype, whereby a user touches a

changes on the GUI

capacitive sensor and the sensor data is visualized on the
sensor in real-time by the use of an iPad.

Figure 10: The chosen song gets dragged and dropped on a
spot of the tuning knob. The action overrides the previously
linked song or radio at this spot.
Figure 8: A user operates the GUI. The
user looks through the available songs
and online radios.

Figure 9: A user draws a line from the
radio to a speaker in order to link the

Smarter Objects can couple all kinds of services and
functions of objects. Smarter Objects have so called
“tags” at the corner of their GUIs (see Figure 15).
These tags are used to connect different functions of
smart objects. The interconnection occurs by touching a
tag on the GUI of one smart object and dragging it to
the tag of another smart object. For example the
volume knop of a radio could be connected with the
blending functionality of a blender. A line representing
this connection is drawn between the two tags. For
example, the slider functionality of a toaster can be
connected with the speaker of an alarm clock in such a
way that if the toaster is ready the alarm clock rings.

speaker with the radio.

In addition to connections between smart objects,
logical virtual objects can be placed in the GUI space as

well through the use of data flow programming (see
Figure 16). For example a virtual clock object can signal
the coffee machine to turn on or a new Facebook
message can switch the light on.
The Smarter Objects concept can be used to set up and
understand devices that are too small to support
different physical affordances or show all functionalities
on its surface. For example, devices that one wears on
the body like watches, jewelry and wristbands. The
setup of such devices is complicated, as they lack
enough space for buttons and screens. By avoiding
complex functionality on the device, small ultra low
power devices can be built that still provide the
capacity for complex functionality. For example, a
simple sensor can collect environmental data and
visualize all its data through the use of a superimposed
GUI (see Figure 11). In such cases, the Smarter
Objects interface can be used to increase the interface
space of such objects. Once the device is set up with
relations, macros and programs, it can be used to one’s
desire with a minimal interface.

Implementation

Figure 12: Once the line is drawn and
the finger released, the devices are
linked.

Figure 13: The speaker plays now the
radio music. The line can be cut with a
swipe gesture to unlink the devices.

Figure 14: Speaker with Radio are now
programmed with a GUI.

The TUI and the GUI are tied together through a server
system. All changes on the TUI have real time influence
on the GUI and vice versa. Whenever an action is
performed at one of the interfaces a message get sent
to the server. The server then sends it to the other
interface in order to synchronize the states. The
augmented GUI is realized with the Qualcomm Vuforia
framework [14] that can use any image as a marker
and project a 3D scene on top if it. The GUI is
programmed with open frameworks. The Touch Device
running the GUI is connected with the server via WIFI
and the software uses the Open Sound Control protocol
(OSC) to communicate with the server. The physical
representation of the Smarter Object uses a WiFly
RN‑131 Wifi module and an Atmega32U4
microprocessor to send the TUI data via the OSC
protocol to the server. As all TUI components basically
consist of sliders, push buttons and rotation knobs, the
system is engineered to be flexible enough that any
object with electronic components can become a part of
the interaction.

Usage Scenarios
Kitchen
In the kitchen, Smarter Objects can help to operate
devices needed for following a recipe. This means one
can place a pan in the oven and select an oven setting
that has been used before. A mixer can have the
perfect setting for the loved smoothie but only a simple
push button needs to be activated in order to start the
preprogrammed setting. The microwave can be set up
once with a beautiful and simple graphical user
interface that explains all functionalities or even
provides recommendations.

Car
In the car, Smarter Objects can help to individually
customize the functionality of the steering wheel, the
temperature range or the functionality of the radio. This
means less tangible interfaces need to be placed in the
car and all interfaces still remain customizable.
Entertainment
In the entertainment area, a Smarter Object can be
used to simplify the set up of TVs and Set-Top-Boxes
using a graphical user interface. Since the user of a TV
wants to keep the eyes on the screen, a tangible
remote can be programmed using the augmented GUI.
Services, complex tasks and macros can be added to
the tangible keys, so that the experience of operating a
TV becomes more intuitive. Smarter Objects can also
be used to simplify the connections between different
media devices by making them virtual and
customizable.
Garden Tools
Smarter Objects can help to check gas levels on
lawnmowers or set up parameters for the blade speed
as well specific patterns. Later this functionality can be
accessed using a simple rotation knob on the
lawnmower. Drilling machines can be set up without a
deep understanding of the task. A user can set up the
material to drill in the graphical interface that also tells
him how to operate this setup in the right way.
Industry
In a production plant, Smarter Objects can help plan
and program production processes directly connected
to tangible interfaces used in such productions. The
settings and reference data for such processes can be
programmed using the graphical interface without any

additional screens on the tools. Later, those tools and
interfaces operate according to the setup preferences.

[4] Lifton, J., Dual Reality: An Emerging Medium, PHD
Thesis MIT Media Lab 2007.
[5]

Future scenarios

Figure 15: A Sketch to illustrate
Tags that are shown in a graphical
user interface augmented on top of a
physical object. These tags are used
to program the connections between
Smarter Objects.

The Smarter Objects system can be used with any
device that can act as a visual input and output device.
This means that instead of using see-through AR
technology available on today’s tablets and smart
phones we could also use transparent displays, rooms
that use technology like the cave, augmented reality
glasses like Google Glass or the projected AR devices
envisioned in the MIT Fluid Interfaces Group [15].
Devices that do not have a touch interface may act as
direct manipulation interfaces, whereby the augmented
interface is controlled on the surface of the physical
object. Connected to the Internet, a user could share
ownership of Smarter Objects with other people and
create a social network of objects. Such a network will
generate timelines for all connected objects as well as
track their usage and their connections to other
objects. By sharing ownership, a user can share
information to teach and learn about objects.

Acknowledgements
Figure 16: A Sketch to illustrate a
Data-Flow-Programming environment
augmented in to physical space in
order to program the behavior of
smarter objects.

We would like to thank the Fluid Interfaces Group for
their insightful remarks as well as Simon Olberding,
Nan-Wei Gong and James Hobin for all their help.

References
[1] Underkoffler, J., The I/O Bulb and the Luminous
Room, PHD Thesis MIT Media Lab 1999.
[2] Gatenby, D., Galatea: Personalized Interaction with
Augmented Objects, MS Thesis MIT Media Lab 2005.
[3] Kestner, J., Social networks for lonely objects, MS
Thesis MIT Media Lab 2000.

Krikorian, R., Internet 0, MS MIT Media Lab 2004.

[6] Tani, M., Yamaashi, K., Tanikoshi, K., Futakawa,M.,
and Tanifuji, S., Objectoriented video: interaction with
real-world objects through live video, Proc. CHI 1992,
pp. 593-598.
[7] Liu, C. Huo, S. Diehl, J. Mackay, W. BeaudouinLafon, M., Evaluating the Benefits of Real-time
Feedback in Mobile Augmented Reality with Hand-held
Devices, CHI’12.
[8] Lee, J. Kim, J. Kim, J. Kim and Kwak, J. A Unified
Remote Console Based on Augmented Reality in a
Home Network Environment, ICCE’07.
[9] Seifried, T., Haller, M., Scott,S., Perteneder, F.,
Rendl, C., Sakamoto, D., and Inami, M., CRISTAL:
Design and Implementation of a Remote Control
System Based on a Multi-touch Display, Proc. ITS 2009,
pp. 37-44.
[10] Feiner, S., MacIntyre, B., Seligmann, D.,
Knowledge-Based Augmented Reality, Communication
of the ACM July 1993/Vol. 36, No. 7 Page 53-62.
[11] Henderson, S. Feiner, S., Augmented Reality in the
Psychomotor Phase of a Procedural Task, ISMAR’11, pp.
191-200.
[12] Hakkarainen, M., Woodward, C. Billinghurst, M.,
Augmented Assembly using a Mobile Phone, ISMAR’08,
pp. 167 – 168.
[13] Van Krevelen, D., Poelman, R., A Survey of
Augmented Reality Technologies, Applications and
Limitations, The International Journal of Virtual Reality
2010, Vol. 9, No. 2, pp. 1-20.
[14] Qualcomm Vuforia,
http://www.qualcomm.com/Vuforia
[15] Mistry, P., Maes, P. Chang, L., WUW - Wear Ur
World - A Wearable Gestural, Proc. CHI’09 extended
abstracts on Human factors in computing systems.
ACM, 4111-4116.

