RunPlay: Action Recognition Using Wearable Device Apply
on Parkour Game
Shi-Yao Wei
National Taiwan University
Institute for Information
Industry
Taipei, Taiwan
sywei@iii.org.tw

Chen-Yu Wang
National Taiwan University
Taipei, Taiwan
benben994@hotmail.com

Ting-Wei Chiu
National Taiwan University
Taipei, Taiwan
s8803111@gmail.com

Yi-Ping Lo
Institute for Information
Industry
Taipei, Taiwan
twmaypl@gmail.com

Zhi-Wei Yang
National Taiwan University
Taipei, Taiwan
r04922169@ntu.edu.tw

Hsing-Man Wang
Institute for Information
Industry
Taipei, Taiwan
hmwang@iii.org.tw

Yi-Ping Hung
National Taiwan University
Taipei, Taiwan
hung@csie.ntu.edu.tw
ABSTRACT

INTRODUCTION

In this paper, we present an action recognition system which
consists of pressure insoles, with 16 pressure sensors, and an
inertial measurement unit. By analysing the data measured
from these sensors, we are able to recognised several human
activities. In this circumstance, we focus on the detection of
jumping, squatting, moving left and right. We also designed a
parkour game on a mobile device to demonstrate the in-game
control of an avatar by human action.

The most widely used methods for capture human activities
are the motion capture systems, such as OptiTrack and VICON. These systems track human skeleton by using several
InfraRed cameras to track the reflective markers attached on
body. These require the reflective markers to be attached at
precise location, in order to obtain the accurate results. However, precise placement of reflective markers requires experienced and professional technicians. Furthermore, these systems are not portable, they can only be used in particular
spaces which the systems have been set up. Thus, these kind
of motion capture systems are not suitable for daily activities
monitoring.

Author Keywords

Action recognition; activity identification; Inertial
measurement unit (IMU); Pressure insole; Internet of things.

Since the electric circuits and integrated circuits have decreased in size and in manufacturing cost, wearable devices
are able to be developed rapidly. Wearable devices have been
widely applied in various fields including physiological data
collection from human body (see for example [5]). Furthermore, these devices have also been utilised on human activities recognition [7, 3, 6, 8, 4]. These devices use either/both
inertial measurement units or/and pressure sensors to measure
data; by analyzing these data they build action recognition algorithms and activities models of the user. These personal
models are able to be used for disease detection and accident
prevention. For example, when a user changed his normal
walking gait, this may results from the diabetes [2].

ACM Classification Keywords

B.1.1. Control Structures and Microprogramming (D.3.2):
Control Design Styles; J.3. Life and Medical Sciences; J.7.
Computers in Other System (C.3): Command and control;
K.8.0. Personal Computing: General

Permission to make digital or hard copies of part or all of this work
for personal or classroom use is granted without fee provided that
Permission
to make
or hard copies
of all or
of this work for personal or
copies
are not
madedigital
or distributed
for profit
or part
commercial
classroom use
granted
without
provided
arecitation
not madeon
or the
distributed
advantage
andisthat
copies
bearfee
this
noticethat
andcopies
the full
for profit
commercial for
advantage
and that
copies bearof
this
notice
andmust
the full citafirst
page.orCopyrights
third-party
components
this
work
tion on the first page. Copyrights for components of this work owned by others than
be
honored.
all other
uses, contact
the isOwner/Author.
ACM
must beFor
honored.
Abstracting
with credit
permitted. To copy otherwise, or reCopyright
is held
by theorowner/author(s).
publish, to post
on servers
to redistribute to lists, requires prior specific permission
and/or a fee.
RequestOctober
permissions
from2016,
permissions@acm.org.
UIST'16
Adjunct,
16-19,
Tokyo, Japan
UIST’16
Adjunct, October 16–19, 2016, Tokyo, Japan.
ACM
978-1-4503-4531-6/16/10.
Copyright c 2016 ACM ISBN 978-1-4503-4531-6/16/10 ...$15.00.
http://dx.doi.org/10.1145/2984751.2985731

To the best of our knowledge, the existing action recognition algorithms are not very efficient on jumping and squatting recognition. Therefore, in this paper, we propose new
activities recognition algorithms which will focus on jump-

http://dx.doi.org/10.1145/2984751.2985731

133

ing and squatting. Furthermore, we also present recognition
methods for other activities, including moving to the left and
right, to complete the actions we need in the demonstration.to
complete the actions we need in the demonstration, including
moving to the left and right.

Squatting detection

By comparison of the pressure distribution when standstill
and squatting (Figure 2b & 2c), the pressure are mainly located at the front of both feet rather than the whole feet surface. However, the pressure distributions are similar when
squatting and moving centre of mass to the front, therefore,
in order to avoid misjudgement, the squatting action is identified by not only pressure located at the front of both feet and
also the main pressure point locates at the big toe (Figure 2c).

ACTION RECOGNITION DEVICES

A pair of pressure insoles are attached on shoos (see Figure 1a). Each pressure insole consists of 16 pressure sensors
and a motion sensor which includes an accelerometer, a gyroscope, and a magnetometer. The data measured from pressure
and motion sensor are transferred to mobile phone wirelessly
via Bluetooth connection (Figure 1b).

Moving detection

In this demonstration, we also design the movement actions,
move to the left and right (See Figure 2d & 2e). These are also
identified by pressure distribution on both feet. When moving
to the left, the pressure on the right foot will drop to zero
as the right foot has been risen; simultaneously, the pressure
on the left increased to reach approximately the equivalent
of the total amount of pressure on both feet when standing.
Conversely, raising the left foot will result in moving to the
right.
DEMONSTRATION

(a)

We developed a intuition Parkour game both on mobile devices and Gear VR based on “3D infinite runner toolkit”
from unity [1]. Figure 2 and 3a show that user uses wearable devices to play Parkour game on mobile phone and Gear
VR. The avatar is running on a track to collect the coins
and there are several kind of obstacles appeared. In order to
pass through the obstacles, the four actions, jumping, rolling,
move to the left lane and move to the right lane are applied
(see Figure 3b – 3e.). These actions are controlled by the
actions introduced in previous section.

(b)

Figure 1: Photo of the system. (a) The pressure insole with
accelerometer attached on shoos. The pressure sensors are
placed at the bottom of the shoos. (b) The mobile app and the
extension monitor (for demonstration).

ACTION RECOGNITION TECHNIQUES
Jumping detection

The jumping action is detected using the accelerometer. First,
the reference axis is determined as the opposite direction of
the gravity when standstill. Then acceleration vectors, the
values of acceleration in three directions obtained during the
movement, are projected on the reference axis. If the projection acceleration was larger than a threshold (we set at 12
m/s2 ), then the action is identified as jumping (see Figure
2a).

(a)

(b)

(c)

(d)

(e)

Figure 3: The screen shot of the action in the game. (a) Jumping, (b) rolling, (c) move to the left, and (d) move to the right.
CONCLUSION

(a)

(b)

(c)

(d)

We present a action recognition system using wearable devices, which consist of pressure insole and inertial measurement unit. In this paper, we focus on the actions including
jumping, squatting and moving to the left or right. Jumping
is determined by the data from accelerometer in the IMU and
squatting, moving to the left and right are determined by the
pressure distribution on the pressure insole. We developed a
intuition Parkour game to demonstrate the correctness of the
action recognition algorithms.

(e)

Figure 2: Action recognition techniques for (a) jumping (b)
standing and (c) squatting. Jumping is identified using acceleration on reference axis and squatting is identified by the
pressure distribution on feet.

134

4. Dong, B., and Biswas, S. Wearable networked sensing for
human mobility and activity analytics: A systems study.
2012 4th International Conference on Communication
Systems and Networks, COMSNETS 2012 (2012), 1–6.

ACKNOWLEDGMENTS

This study is conducted under the “III Innovative and
Prospective Technologies Project” of the Institute for Information Industry which is subsidised by the Ministry of Economy Affairs of the Republic of China.

5. Patel, S., Park, H., Bonato, P., Chan, L., and Rodgers, M.
A review of wearable sensors and systems with
application in rehabilitation. Journal of
NeuroEngineering and Rehabilitation 9, 1 (2012), 21.

We thank Chih-Chun Ma, Mr. for assistance and comment
with left and right movement recognition techniques, and
Ying Chen, Miss for proofreading the manuscript.

6. Peng, Z., Cao, C., Liu, Q., and Pan, W. Human walking
pattern recognition based on KPCA and SVM with
ground reflex pressure signal. Mathematical Problems in
Engineering 2013 (2013).

REFERENCES

1. 3D infinite runner toolkit, 2014.
2. Brach, J. S., Talkowski, J. B., Strotmeyer, E. S., and
Newman, A. B. Diabetes Mellitus and Gait Dysfunction:
Possible Explanatory Factors. Physical Therapy. 88, 11
(2008), 1365–1374.

7. Sugimoto, C., Tsuji, M., Lopez, G., Hosaka, H., Sasaki,
K., Hirota, T., and Tatsuta, S. Development of a behavior
recognition system using wireless wearable information
devices. In 2006 1st International Symposium on Wireless
Pervasive Computing (2006).

3. Choudhury, T., Hightower, J., Lamarca, A., Legrand, L.,
Rahimi, A., Rea, A., Hemingway, B., Koscher, K.,
Landay, J. a., Lester, J., and Wyatt, D. An embedded
Activity Recognition system. IEEE Pervasive Computing
7, 2 (2008), 32–41.

8. Wang, Y., Jiang, X., Cao, R., and Wang, X. Robust Indoor
Human Activity Recognition Using Wireless Signals.
17195–17208.

135

