Depth Based Shadow Pointing Interface for Public Displays
Jun Shingu*
Fuji Xerox Co., Ltd.
6-1 Minatomirai, Nishi-ku,
Yokohama, Kanagawa, JAPAN
jun.shingu@fujixerox.co.jp
*

Patrick Chiu†

Sven Kratz† Jim Vaughan† Don Kimber†
†
FX Palo Alto Laboratory, Inc.
3174 Porter Drive
Palo Alto, CA, USA
{chiu, kratz, jimv, kimber}@fxpal.com

Figure 1: Users’ virtual shadows are overlaid on
display contents. Using detected pointer (green circle),
users interact with the contents.

Figure 2: Our virtual shadow is generated as if there is an
angled virtual sun light from behind. The nearest point to the
display is interpreted as a pointer.

ABSTRACT

We propose a robust pointing detection with virtual shadow
representation for interacting with a public display. Using a
depth camera, our shadow is generated by a model with an
angled virtual sun light and detects the nearest point as a
pointer. The position of the shadow becomes higher when
user walks closer, which conveys the notion of correct
distance to control the pointer and offers accessibility to the
higher area of the display.

display, such as digital signage. A touchless interface is
effective for large display especially in the case when
people cannot reach the display. Using a depth image
sensor, our system shows virtual shadows of users on the
displayed content and supports interaction by the shadow
with a control pointer (Figure 1). A unique feature of our
virtual shadow is that it is generated as if there is a virtual
sun light from behind of the person (Figure 2). This makes
the position of shadow becomes lower when the person is
far from the display, and becomes higher when the person
gets closer. This feature has benefits of awareness of
distance from the display and accessibility to the higher
portion of the display.

Author Keywords

Large display; depth based interaction; pointing interface.
ACM Classification Keywords

H.5.2. Information interfaces and presentation: Input
devices and strategies

Some existing work also propose showing shadows or
silhouettes of users for interaction on a large display.
Multiple persons’ shadows naturally provide feedback for
each person’s operation [2, 3]. And displaying shadows has
the effect of gaining attention of others around a digital
signage in a street [1].

INTRODUCTION

We demonstrate a robust pointing interface for a public

Our shadow technique conveys a suitable distance to
interact with the display content from. When users are too
far from the display, no shadow is shown on the display. It
can prevent users from getting outside the field of view of
the sensor. We also offer a depth based pointing control,
which detects the nearest point of an object from the display
as the pointer. As Figure 2 shows, we defined an operation
area at a certain distance from the display, and part of the

Permission to make digital or hard copies of part or all of this work for
personal or classroom use is granted without fee provided that copies are
not made or distributed for profit or commercial advantage and that copies
bear this notice and the full citation on the first page. Copyrights for thirdparty components of this work must be honored. For all other uses, contact
the Owner/Author.
Copyright is held by the owner/author(s).
UIST'16 Adjunct, October 16-19, 2016, Tokyo, Japan
ACM 978-1-4503-4531-6/16/10.
http://dx.doi.org/10.1145/2984751.2985710

79

[Step 2] As Figure 2 illustrates, the 3D point cloud is
transformed and projected onto display surface plane as if
there is a virtual sun light from behind. The light source is
angled 30 degrees from horizontal. The shadow image is
vertically offset by a constant value, which is determined by
a designed distance to the display.
[Step 3] The pixel color of the shadow image is determined
by the distance from the display. When it is in the operation
area, the color becomes red (it is gray otherwise).
[Step 4] For the pixels inside of the operation area, the
closest pixel to the display becomes the pointer. A green
circle pointer is added on the shadow image.
[Step 5] The shadow and pointer is transparently overlaid
on the display contents.
Display Contents with Swipe Action Buttons

We created sample contents to be controlled by our shadow
pointing UI. The content pages are information of products
with button based navigation, which have a “Show More
Details” button for each item and a “Go Back” button. Our
button interprets a horizontal swipe action as a clicking
event. When the pointer is placed over a button, a left or
right arrow graphic is shown. Then the user moves the
pointer to left/right to activate the button.

Figure 1: Our shadow is displayed lower when the distance is
far like (a), but gets higher when it is closer as (b). Even a
short height user, like a person on wheel chair, also be able to
control with the same settings.

shadow inside of the area is shown in red color. Users can
notice the invisible operation area with the color. By putting
a hand inside of the area, users can interact with contents
using the detected pointer, which is shown as a green circle.
Our shadow has the feature that the position of shadow
becomes higher when the user is closer. As Figure 3 shows,
even at a low height, the user is able to reach the high parts
of display by going closer. This is similar to [3], although
they use a perspective light source behind the user and the
shadow becomes larger when the user steps back from the
display.

PRELIMINARY TEST AND DEMONSTRATION

We tested the system in our lab. We confirmed that users
can find a correct position to interact and control the swipe
button with the pointing UI easily. Our pointing detection
simply takes the nearest point and worked robustly with
multiple users, because it does not need human body or
hand detections, which can be unstable with crowded
situations.

SYSTEM DESIGN

We implemented the shadow pointing UI to control buttons
on a large display for navigating the contents.

As found in [1], a user who actively interacted is positioned
in front of the display, and audiences usually stood behind
her/him. Because the audiences’ shadows are shown at a
lower position than the interactor’s, the interaction is not
disturbed by the audiences’ shadows. Although currently
only one user can control the display at the same time, by
moving closer or stepping back, changing of an interactor in
groups can take place smoothly.

Hardware Settings

Our display (50 inches) is setup in portrait mode. A
Kinect® for Windows®1 depth sensor is placed on it. We
calibrated the 3D position and angle of the sensor. The
sensor is connected to a PC, which creates and shows the
shadow and control pointer on the displayed contents.

For our demonstration, attendees can experience shadow
pointing UI with the prototype system.

Generating Shadow

From the sensed depth image, the shadow graphic is created
as following:

REFERENCES

1.Müller, J., Walter, R., Bailly, G., Nischt, M. and Alt, F.,
Looking glass: a field study on noticing interactivity of a
shop window. In Proc. CHI 2012, 297-306.

[Step 1] The captured depth image is converted into 3D
point cloud in world coordinates by the position/angle of
the sensor.

2. Nutsi, A. and Koch, M., Multi-User Usability Guidelines
for Interactive Wall Display Applications.
In Proc. PerDis 2015, 233-234.

1
Microsoft and Kinect are either registered trademarks or
trademarks of Microsoft Corporation in the United States
and/or other countries.

3. Shoemaker, G., Tang, A. and Booth, K. S., Shadow
Reaching: A New Perspective on Interaction for Large
Wall Displays. In Proc. UIST 2007, 53-56.

80

