Design and Evaluation of EdgeWrite Alphabets
for Round-Face Smartwatches
Keiichi Ueno, Kentaro Go, Yuichiro Kinoshita
University of Yamanashi
[ g16tk002 | go | ykinoshita ]@yamanashi.ac.jp
s

r

ABSTRACT

This study presents a project aimed at designing and evaluating a unistroke gesture set of alphanumeric characters targeting round-face smartwatches. We conducted a user study with
10 participants to generate the basic gesture design for 40
characters. For each character, we measured the preference
and agreement scores and uncovered any challenges faced
in designing unistroke gestures for round-face smartwatches.
We developed a gesture recognizer using machine learning,
which used a backpropagation mechanism to evaluate the designed gestures. Using the gesture recognizer, we collected
80,000 gesture data, and evaluated them with 5-fold crossvalidation. The obtained mean recognition rate was 92.14%.

(a)

(b)

Figure 1. Input gestures

Figure 2. Experimental device

for text entry on small devices. However, with the original design of the alphanumeric characters for EdgeWrite, a rectangular input area was employed, i.e., differently shaped input
areas were not supported. This provides us with an opportunity to investigate different design space for EdgeWrite from
the viewpoint of form factor: the use of rounded spaces.

Author Keywords

Text entry; unistrokes; edges; smartwatches.

METHOD

ACM Classification Keywords

Approach

In our approach, the user traces the edge of a circular input
area with a finger. Precisely, the user enters an alphanumeric
character with a unistroke gesture similar to the shape of the
intended character. The following example shows the input
procedure for entering the letter “r”: (1) Imagine the shape
of the letter “r”, and place his/her finger on the screen at the
starting point for drawing; (2) Draw the “r” shape by tracing
the edge with the finger; (3) completed drawing the letter, and
release the finger from the screen edge; and (4) The letter “r”
is displayed on the screen. The resulted gesture is expected
to form a shape similar to that the letter “r” (Figure 1a).

H.5.2. Information interfaces and presentation (e.g. HCI):
User Interfaces.
INTRODUCTION

Text entry is a basic interaction but cumbersome task in the
contemporary urban life. In particular, small devices such
as smartwatches make it difficult to type with tiny keys on
a small touchscreen keyboard and require several actions.
Smartwatches are now used in daily life. Entering text while
conducting another task such as walking usually happens at a
slower rate because the watch face shakes and the user cannot focus on the task. This situation is a typical example of a
situationally induced impairment and disability (SIID) [1].

User generated gestures

The purpose of this investigation was to determine whether
users can draw gestures using the proposed method. We recruited 10 participants aged from 21 to 23 (M = 22.1) years.
All of them were right-handed. An Android Nexus 5 (4.95
inches, 1080×1920 pixels) was used as the input device. Its
display was covered with a 1-mm-thick polypropylene plate
with a 1.3-inch hole in the center imitating the edge of a
round-face smartwatch (Figure 2).

EdgeWrite [2] is a prominent approach in SIID situations.
Compared with other small-screen text-entry methods such as
ZoomBoard [3], with EdgeWrite, the user draws a unistroke
gesture with his/her finger pressed on the physical screen
edges of an input device. Because the corners and edges
have physical boundaries, the user can enter text in two ways:
without any visual contact and with an unstable device and
unsupported hands. For these reasons, EdgeWrite is suitable

The participants were asked to draw a unistroke gesture to
best fit the shape and the drawing order for a presented character, tracing the edge of the round-shaped input area. They
were also asked to distinguish between the gestures of characters that were similar in shape; it was assumed that some
characters could create the same unistroke gestures, such as
“h” and “n.” Forty characters, including alphanumeric characters and punctuation marks (comma, period, space, and
backspace), were presented, and their presentation order was

Permission to make digital or hard copies of part or all of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for third-party components of this work must be honored.
For all other uses, contact the Owner/Author.
Copyright is held by the owner/author(s).
UIST’16 Adjunct, October 16-19, 2016, Tokyo, Japan
ACM 978-1-4503-4531-6/16/10.
http://dx.doi.org/10.1145/2984751.2984757

177

randomized. Each participant conducted 12 trials. Using a 7point Likert scale (7 = strongly agree), participants rated their
preference for the gesture they created.

The basic gesture design

Based on the gestures created in the final trial, we designed
the basic gestures of alphanumeric characters for round-face
smartwatches. The designed gesture of the character “r” is
shown in Figure 1a and the complete list can be seen at
http://www.golab.org/p/redgewrite.html. To design the basic
gestures, we selected gestures with higher agreement scores
unless they had no overlapping gestures. However, if they
had an overlapping gesture, we decided on the gesture based
upon the preference scores: the one with the highest score
was selected. All the participants were unable to create distinguished gestures for the alphabetical character “o” and the
numerical character “0.” Thus, we artificially designed a gesture for “0” similar to that of original EdgeWrite. As the basic gesture design works in the default setting, we developed
a recognizer to conduct user tests of the design.

RESULT
Preference

On the first trial, the mean preference scores for the characters
“c,” “o,” “u,” “0,” and “9” with the standard deviation given
in parentheses were 6.90 (0.30), 6.70 (0.64), 6.30 (1.00), 6.40
(0.80), and 6.20 (0.60), respectively. These are all higher than
a score of 6. Because these characters contain curvy lines,
users naturally fitted them to the circular edge being used. In
contrast, the scores for “f,” “m,” “t,” “x,” “4,” and “8” were
3.50 (1.20), 3.90 (0.70), 3.20 (1.33), 3.00 (1.10), and 3.10
(1.70), respectively. They are all lower than a score of 4 for
the first trial. These characters comprise crossed lines (“f,”
“t,” “x,” “4,” and “8”) or three parallel lines (“m”), which
makes them more difficult to fit to the circular edge. Furthermore, a Wilcoxon signed-ranks test indicated that the preference was stronger in the final trial (Mdn = 6) than in the
first trial (Mdn = 5), Z = 9.62, p < 0.001, and r = 0.34. This
means that the participants adjusted their drawing behavior
and attitude during the trials.

GESTURE RECOGNIZER AND EVALUATION

To validate the gesture design, we developed a gesture recognizer with machine learning using a backpropagation mechanism. The gesture recognizer was written in Java using the
Android NDK, which calls a method of Fast Artificial Neural
Network Library. Using the gesture recognizer, we conducted
a gesture recognition test and considered the same participants as those who had participated in the gesture generation
test. We collected training data including 20 sets of 40 characters per participant. Subsequently, we evaluated them with
5-fold cross-validation. The resulted mean recognition rate
was 92.14% and is largely accepted as a default value even
though further adjustment will be required.

Agreement

We classified gestures drew by the participants in the final
trial into groups with similar shapes as agreed by the participants. Classification was conducted by two researchers including the first author. If the two researchers found difficulties in judging a certain gesture, two more researchers were
asked to judge. We then calculated the agreement score (Ar )
based on the study by Wobbrok et al. [4] using the formula:
P
|Pi | 2
Ar = Pi ⊆Pr ( |P
) , where r is any character (e.g., the letr|
ter “a”) in the set of all characters R, Pr is the set of proposed
gestures for the character, and Pi is a subset of identical gestures from Pr . The agreement score runs from 0 to 1, with
score is equal to 1 indicating that all the participants drew the
same gesture.

CONCLUSION

In this study, we investigated basic gestures for EdgeWrite
targeting round-face smartwatches with the goal of expanding the design space for text-entry methods in SIID situations.
Based on the participants preferences and agreement scores,
we designed basic designs for gestures of alphanumeric characters in addition to highlighting the challenges when designing gestures for round-face smartwatches. We also developed
a gesture recognizer to evaluate the designs. In our future
study, we may consider designing online learning systems to
achieve a higher accuracy of character recognition.

Among the higher preference group (“c,” “o,” “u,” “0,” and
“9”), the characters “c,” “o,” “0,” and “9” obtained higher
agreement scores; however, “u” had a slightly lower score
(0.52). As we did not restrict characters to being either capitalized or in lowercase, it is possible that the participants
might have imagined different shapes (e.g.,“u” or “U”). In
other words, even if a participant marked a higher preference
score for a gesture of a certain character, its agreement score
can be lower than that obtained when each participant created a unique gesture. Interestingly, while the character “s”
demonstrates a lower preference score, its agreement score is
1.0; all the participants created the same gesture. The character “s” is seemingly hard to draw in the circular input area
because its shape comprises two opposite semicircular arcs
with vertical displacement. Nevertheless, drawing it was easy
for the participants who successfully traced it in the circular
input area by running his/her fingertip counterclockwise from
the upper right to the lower right and then going clockwise to
the lower left (See Figure 1b).

REFERENCES

1. Sears, A. and Young, M. Physical Disabilities and
Computing Technologies: An Analysis of Impairments.
In Human-Computer Interaction Handbook, LEA, pp.
482-503, 2002.
2. Wobbrock, J. O., Myers, B., and Kembal, J. A.
EdgeWrite: A Stylus-based text entry method designed
for high accuracy and stability of motion. In Proc. ACM
UIST ’03, pp. 61-70, 2003.
3. Oney, S., Harrison, C., Ogan, A., and Wiese, J.
ZoomBoard: A diminutive qwerty soft keyboard using
iterative zooming for ultra-small devices. ACM CHI ’13,
pp. 2799-2802, 2013.
4. Wobbrok, J. O., Aung, H. H., Rothrok, B., and Myers,
B. A. Maximizing the guessability of symbolic input.
ACM CHI ’05, pp. 1869-1872, 2005.

178

